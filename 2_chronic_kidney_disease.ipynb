{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aff056e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.io import arff\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "os.makedirs('outputs/figures', exist_ok=True)\n",
    "os.makedirs('outputs/results', exist_ok=True)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35794885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "os.makedirs('outputs/figures', exist_ok=True)\n",
    "os.makedirs('outputs/results', exist_ok=True)\n",
    "os.makedirs('outputs/gridsearch', exist_ok=True)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "print(\"✓ Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c0afe",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a11298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CKD data\n",
    "df = pd.read_csv('kidney_disease/chronic_kidney_disease.csv')\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['classification'].value_counts())\n",
    "print(f\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Encode target variable (Binary: 0 = notckd, 1 = ckd)\n",
    "df['classification'] = df['classification'].map({'notckd': 0, 'ckd': 1})\n",
    "\n",
    "# Separate numeric and categorical columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target from numeric cols if present\n",
    "if 'classification' in numeric_cols:\n",
    "    numeric_cols.remove('classification')\n",
    "\n",
    "# Impute missing values\n",
    "# Numeric: median\n",
    "if numeric_cols:\n",
    "    imputer_num = SimpleImputer(strategy='median')\n",
    "    df[numeric_cols] = imputer_num.fit_transform(df[numeric_cols])\n",
    "\n",
    "# Categorical: most frequent\n",
    "if categorical_cols:\n",
    "    imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "    df[categorical_cols] = imputer_cat.fit_transform(df[categorical_cols])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop('classification', axis=1)\n",
    "y = df['classification']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\n✓ Data preprocessed\")\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Class distribution - Train: {np.bincount(y_train)}\")\n",
    "print(f\"Class distribution - Test: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5b8ff6",
   "metadata": {},
   "source": [
    "## 2. Define Hyperparameter Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bed054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grids (same as Census for consistency)\n",
    "param_grids = {\n",
    "    'KNN': {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11, 15, 21],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'max_iter': [1000]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1]\n",
    "    },\n",
    "    'MLP': {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (100, 50), (100, 100), (150, 100, 50)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'learning_rate': ['constant', 'adaptive'],\n",
    "        'max_iter': [500]\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'max_depth': [3, 5, 7, 10, 15, 20, None],\n",
    "        'min_samples_split': [2, 5, 10, 20],\n",
    "        'min_samples_leaf': [1, 2, 4, 8],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    'Naive Bayes': {\n",
    "        'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3]\n",
    "    }\n",
    "}\n",
    "\n",
    "classifiers = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'SVM': SVC(random_state=42),\n",
    "    'MLP': MLPClassifier(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "print(\"✓ Hyperparameter grids defined\")\n",
    "print(f\"\\nTotal classifiers: {len(classifiers)}\")\n",
    "for name, grid in param_grids.items():\n",
    "    total_combinations = np.prod([len(v) for v in grid.values()])\n",
    "    print(f\"{name}: {len(grid)} hyperparameters, {total_combinations} combinations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7982ca6b",
   "metadata": {},
   "source": [
    "## 3. Perform GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3122af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results = {}\n",
    "best_models = {}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CHRONIC KIDNEY DISEASE - HYPERPARAMETER SENSITIVITY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for name in classifiers.keys():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"GridSearchCV: {name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    clf = classifiers[name]\n",
    "    param_grid = param_grids[name]\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        clf, \n",
    "        param_grid, \n",
    "        cv=5, \n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    grid_results[name] = {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'cv_results': grid_search.cv_results_,\n",
    "        'all_scores': grid_search.cv_results_['mean_test_score'],\n",
    "        'std_scores': grid_search.cv_results_['std_test_score']\n",
    "    }\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    \n",
    "    y_pred = grid_search.best_estimator_.predict(X_test_scaled)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    score_variance = np.var(grid_search.cv_results_['mean_test_score'])\n",
    "    score_std = np.std(grid_search.cv_results_['mean_test_score'])\n",
    "    score_range = np.max(grid_search.cv_results_['mean_test_score']) - np.min(grid_search.cv_results_['mean_test_score'])\n",
    "    \n",
    "    grid_results[name]['test_accuracy'] = test_accuracy\n",
    "    grid_results[name]['test_f1'] = test_f1\n",
    "    grid_results[name]['variance'] = score_variance\n",
    "    grid_results[name]['std'] = score_std\n",
    "    grid_results[name]['range'] = score_range\n",
    "    \n",
    "    print(f\"Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test F1-Score: {test_f1:.4f}\")\n",
    "    print(f\"\\nHyperparameter Sensitivity:\")\n",
    "    print(f\"  Variance: {score_variance:.6f}\")\n",
    "    print(f\"  Std Dev: {score_std:.6f}\")\n",
    "    print(f\"  Range: {score_range:.4f}\")\n",
    "    print(f\"\\nBest Parameters:\")\n",
    "    for param, value in grid_search.best_params_.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"✓ GridSearchCV completed\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dbf1c3",
   "metadata": {},
   "source": [
    "## 4. Sensitivity Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea09049",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_summary = pd.DataFrame({\n",
    "    'Classifier': list(grid_results.keys()),\n",
    "    'Best CV Score': [grid_results[name]['best_score'] for name in grid_results.keys()],\n",
    "    'Test Accuracy': [grid_results[name]['test_accuracy'] for name in grid_results.keys()],\n",
    "    'Test F1': [grid_results[name]['test_f1'] for name in grid_results.keys()],\n",
    "    'Variance': [grid_results[name]['variance'] for name in grid_results.keys()],\n",
    "    'Std Dev': [grid_results[name]['std'] for name in grid_results.keys()],\n",
    "    'Range': [grid_results[name]['range'] for name in grid_results.keys()]\n",
    "})\n",
    "\n",
    "sensitivity_summary = sensitivity_summary.round(4)\n",
    "sensitivity_summary = sensitivity_summary.sort_values('Variance', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HYPERPARAMETER SENSITIVITY RANKING - CHRONIC KIDNEY DISEASE\")\n",
    "print(\"=\"*80)\n",
    "print(sensitivity_summary.to_string(index=False))\n",
    "\n",
    "sensitivity_summary.to_csv('outputs/results/ckd_sensitivity.csv', index=False)\n",
    "print(\"\\n✓ Results saved to: outputs/results/ckd_sensitivity.csv\")\n",
    "\n",
    "most_sensitive = sensitivity_summary.iloc[0]['Classifier']\n",
    "least_sensitive = sensitivity_summary.iloc[-1]['Classifier']\n",
    "print(f\"\\nMost Sensitive: {most_sensitive}\")\n",
    "print(f\"Least Sensitive: {least_sensitive}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20afab1",
   "metadata": {},
   "source": [
    "## 5. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1288f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Hyperparameter Sensitivity Analysis - Chronic Kidney Disease Dataset', fontsize=16, fontweight='bold')\n",
    "\n",
    "ax = axes[0, 0]\n",
    "sensitivity_summary.plot(x='Classifier', y='Variance', kind='bar', ax=ax, color='coral', legend=False)\n",
    "ax.set_title('Hyperparameter Variance', fontweight='bold')\n",
    "ax.set_ylabel('Variance')\n",
    "ax.set_xlabel('')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "ax = axes[0, 1]\n",
    "sensitivity_summary.plot(x='Classifier', y='Range', kind='bar', ax=ax, color='skyblue', legend=False)\n",
    "ax.set_title('Score Range', fontweight='bold')\n",
    "ax.set_ylabel('Range')\n",
    "ax.set_xlabel('')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "ax = axes[0, 2]\n",
    "x_pos = np.arange(len(sensitivity_summary))\n",
    "width = 0.35\n",
    "ax.bar(x_pos - width/2, sensitivity_summary['Best CV Score'], width, label='CV Score', color='lightgreen')\n",
    "ax.bar(x_pos + width/2, sensitivity_summary['Test Accuracy'], width, label='Test Accuracy', color='lightcoral')\n",
    "ax.set_title('CV vs Test Performance', fontweight='bold')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(sensitivity_summary['Classifier'], rotation=45)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "ax = axes[1, 0]\n",
    "sensitivity_summary.plot(x='Classifier', y='Std Dev', kind='bar', ax=ax, color='mediumpurple', legend=False)\n",
    "ax.set_title('Standard Deviation', fontweight='bold')\n",
    "ax.set_ylabel('Std Dev')\n",
    "ax.set_xlabel('')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "ax = axes[1, 1]\n",
    "sensitivity_summary.plot(x='Classifier', y='Test F1', kind='bar', ax=ax, color='gold', legend=False)\n",
    "ax.set_title('Test F1-Score', fontweight='bold')\n",
    "ax.set_ylabel('F1-Score')\n",
    "ax.set_xlabel('')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "ax = axes[1, 2]\n",
    "scatter = ax.scatter(sensitivity_summary['Variance'], sensitivity_summary['Test Accuracy'], \n",
    "                     s=200, c=range(len(sensitivity_summary)), cmap='viridis', alpha=0.6, edgecolors='black')\n",
    "for idx, row in sensitivity_summary.iterrows():\n",
    "    ax.annotate(row['Classifier'], (row['Variance'], row['Test Accuracy']), fontsize=8, ha='center', va='bottom')\n",
    "ax.set_title('Sensitivity vs Performance', fontweight='bold')\n",
    "ax.set_xlabel('Variance')\n",
    "ax.set_ylabel('Test Accuracy')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figures/ckd_sensitivity_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Visualizations saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6ee93a",
   "metadata": {},
   "source": [
    "## 6. Save Detailed Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a86f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in grid_results.keys():\n",
    "    cv_results = grid_results[name]['cv_results']\n",
    "    results_df = pd.DataFrame(cv_results)\n",
    "    results_df.to_csv(f'outputs/gridsearch/ckd_{name.replace(\" \", \"_\").lower()}_gridsearch.csv', index=False)\n",
    "\n",
    "print(\"✓ Detailed GridSearch results saved to outputs/gridsearch/\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ Analysis complete for Chronic Kidney Disease dataset\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46749849",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78c9c7a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": " yes value not in ('yes', 'no')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load CKD data from ARFF file\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m data, meta = \u001b[43marff\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloadarff\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mkidney_disease/chronic_kidney_disease_full.arff\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df = pd.DataFrame(data)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Decode byte strings\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/principles_of_ml/venv/lib/python3.13/site-packages/scipy/io/arff/_arffread.py:804\u001b[39m, in \u001b[36mloadarff\u001b[39m\u001b[34m(f)\u001b[39m\n\u001b[32m    802\u001b[39m     ofile = \u001b[38;5;28mopen\u001b[39m(f)\n\u001b[32m    803\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m804\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_loadarff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mofile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    806\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ofile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f:  \u001b[38;5;66;03m# only close what we opened\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/principles_of_ml/venv/lib/python3.13/site-packages/scipy/io/arff/_arffread.py:869\u001b[39m, in \u001b[36m_loadarff\u001b[39m\u001b[34m(ofile)\u001b[39m\n\u001b[32m    865\u001b[39m         row, dialect = split_data_line(raw, dialect)\n\u001b[32m    867\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([attr[i].parse_data(row[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m elems])\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m a = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mofile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[38;5;66;03m# No error should happen here: it is a bug otherwise\u001b[39;00m\n\u001b[32m    871\u001b[39m data = np.array(a, [(a.name, a.dtype) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m attr])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/principles_of_ml/venv/lib/python3.13/site-packages/scipy/io/arff/_arffread.py:867\u001b[39m, in \u001b[36m_loadarff.<locals>.generator\u001b[39m\u001b[34m(row_iter, delim)\u001b[39m\n\u001b[32m    863\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    865\u001b[39m row, dialect = split_data_line(raw, dialect)\n\u001b[32m--> \u001b[39m\u001b[32m867\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\u001b[43mattr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m elems])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/principles_of_ml/venv/lib/python3.13/site-packages/scipy/io/arff/_arffread.py:159\u001b[39m, in \u001b[36mNominalAttribute.parse_data\u001b[39m\u001b[34m(self, data_str)\u001b[39m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data_str\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(data_str)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m value not in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.values)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m:  yes value not in ('yes', 'no')"
     ]
    }
   ],
   "source": [
    "# Load CKD data from ARFF file\n",
    "data, meta = arff.loadarff('kidney_disease/chronic_kidney_disease_full.arff')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Decode byte strings\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col] = df[col].str.decode('utf-8')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['class'].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568d93bb",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99f43df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else 'unknown', inplace=True)\n",
    "    else:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Encode target (Binary: 0 = notckd, 1 = ckd)\n",
    "df['class'] = df['class'].map({'notckd': 0, 'ckd': 1})\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194c32d0",
   "metadata": {},
   "source": [
    "## 3. Train 6 Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb648915",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', random_state=42),\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CHRONIC KIDNEY DISEASE - TRAINING 6 CLASSIFIERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining: {name}\")\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    cv_scores = cross_val_score(clf, X_train_scaled, y_train, cv=5)\n",
    "    \n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'CV Mean': cv_scores.mean(),\n",
    "        'CV Std': cv_scores.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}, F1: {f1:.4f}, CV: {cv_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b00f96",
   "metadata": {},
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa30d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).T.round(4)\n",
    "print(\"\\nFINAL RESULTS - CHRONIC KIDNEY DISEASE\")\n",
    "print(results_df)\n",
    "results_df.to_csv('outputs/results/ckd_results.csv')\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "results_df['Accuracy'].plot(kind='bar', ax=axes[0,0], color='skyblue')\n",
    "axes[0,0].set_title('Accuracy Comparison')\n",
    "axes[0,0].set_ylim([0.7, 1.0])\n",
    "\n",
    "results_df['F1-Score'].plot(kind='bar', ax=axes[0,1], color='coral')\n",
    "axes[0,1].set_title('F1-Score Comparison')\n",
    "axes[0,1].set_ylim([0.7, 1.0])\n",
    "\n",
    "x_pos = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "axes[1,0].bar(x_pos - width/2, results_df['Precision'], width, label='Precision')\n",
    "axes[1,0].bar(x_pos + width/2, results_df['Recall'], width, label='Recall')\n",
    "axes[1,0].set_title('Precision vs Recall')\n",
    "axes[1,0].set_xticks(x_pos)\n",
    "axes[1,0].set_xticklabels(results_df.index, rotation=45)\n",
    "axes[1,0].legend()\n",
    "\n",
    "results_df[['Accuracy', 'Precision', 'Recall', 'F1-Score']].plot(kind='bar', ax=axes[1,1])\n",
    "axes[1,1].set_title('All Metrics')\n",
    "axes[1,1].set_ylim([0.7, 1.0])\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figures/ckd_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "best_model = results_df['Accuracy'].idxmax()\n",
    "print(f\"\\nBest Model: {best_model} with Accuracy: {results_df.loc[best_model, 'Accuracy']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
