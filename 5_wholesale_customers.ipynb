{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8003507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "os.makedirs('outputs/figures', exist_ok=True)\n",
    "os.makedirs('outputs/results', exist_ok=True)\n",
    "os.makedirs('outputs/gridsearch', exist_ok=True)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "print(\"✓ Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd4ce7a",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162104d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wholesale data\n",
    "df = pd.read_csv('wholesale/Wholesale customers data.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "\n",
    "# Product categories\n",
    "product_cols = ['Fresh', 'Milk', 'Grocery', 'Frozen', 'Detergents_Paper', 'Delicassen']\n",
    "\n",
    "# Calculate total spending\n",
    "df['Total_Spending'] = df[product_cols].sum(axis=1)\n",
    "\n",
    "print(f\"\\nTotal Spending statistics:\")\n",
    "print(df['Total_Spending'].describe())\n",
    "\n",
    "# Convert to binary using median split\n",
    "median_spending = df['Total_Spending'].median()\n",
    "df['Spender_Class'] = (df['Total_Spending'] > median_spending).astype(int)\n",
    "\n",
    "print(f\"\\nMedian Spending: {median_spending:.2f}\")\n",
    "print(f\"\\nBinary Class Distribution (1=High Spender, 0=Low Spender):\")\n",
    "print(df['Spender_Class'].value_counts())\n",
    "\n",
    "# Features: Use product categories only\n",
    "X = df[product_cols]\n",
    "y = df['Spender_Class']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\n✓ Data preprocessed\")\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Class distribution - Train: {np.bincount(y_train)}\")\n",
    "print(f\"Class distribution - Test: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf40768",
   "metadata": {},
   "source": [
    "## 2. Define Hyperparameter Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1598e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'KNN': {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11, 15, 21],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'max_iter': [1000]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1]\n",
    "    },\n",
    "    'MLP': {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (100, 50), (100, 100), (150, 100, 50)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'learning_rate': ['constant', 'adaptive'],\n",
    "        'max_iter': [500]\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'max_depth': [3, 5, 7, 10, 15, 20, None],\n",
    "        'min_samples_split': [2, 5, 10, 20],\n",
    "        'min_samples_leaf': [1, 2, 4, 8],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    'Naive Bayes': {\n",
    "        'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3]\n",
    "    }\n",
    "}\n",
    "\n",
    "classifiers = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'SVM': SVC(random_state=42),\n",
    "    'MLP': MLPClassifier(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "print(\"✓ Hyperparameter grids defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777fe159",
   "metadata": {},
   "source": [
    "## 3. Perform GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb9ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results = {}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"WHOLESALE CUSTOMERS - HYPERPARAMETER SENSITIVITY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for name in classifiers.keys():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"GridSearchCV: {name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        classifiers[name], \n",
    "        param_grids[name], \n",
    "        cv=3, \n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    grid_results[name] = {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'cv_results': grid_search.cv_results_,\n",
    "        'test_accuracy': accuracy_score(y_test, grid_search.predict(X_test_scaled)),\n",
    "        'test_f1': f1_score(y_test, grid_search.predict(X_test_scaled)),\n",
    "        'variance': np.var(grid_search.cv_results_['mean_test_score']),\n",
    "        'std': np.std(grid_search.cv_results_['mean_test_score']),\n",
    "        'range': np.ptp(grid_search.cv_results_['mean_test_score'])\n",
    "    }\n",
    "    \n",
    "    print(f\"Best CV: {grid_results[name]['best_score']:.4f}\")\n",
    "    print(f\"Test Acc: {grid_results[name]['test_accuracy']:.4f}\")\n",
    "    print(f\"Sensitivity - Var: {grid_results[name]['variance']:.6f}, Range: {grid_results[name]['range']:.4f}\")\n",
    "\n",
    "print(\"\\n✓ GridSearchCV completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f24aa39",
   "metadata": {},
   "source": [
    "## 4. Summary & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f06b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_summary = pd.DataFrame({\n",
    "    'Classifier': list(grid_results.keys()),\n",
    "    'Best CV Score': [grid_results[n]['best_score'] for n in grid_results],\n",
    "    'Test Accuracy': [grid_results[n]['test_accuracy'] for n in grid_results],\n",
    "    'Test F1': [grid_results[n]['test_f1'] for n in grid_results],\n",
    "    'Variance': [grid_results[n]['variance'] for n in grid_results],\n",
    "    'Std Dev': [grid_results[n]['std'] for n in grid_results],\n",
    "    'Range': [grid_results[n]['range'] for n in grid_results]\n",
    "}).round(4).sort_values('Variance', ascending=False)\n",
    "\n",
    "print(\"\\nSENSITIVITY RANKING - WHOLESALE CUSTOMERS\")\n",
    "print(\"=\"*80)\n",
    "print(sensitivity_summary.to_string(index=False))\n",
    "\n",
    "sensitivity_summary.to_csv('outputs/results/wholesale_sensitivity.csv', index=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Hyperparameter Sensitivity - Wholesale Customers', fontsize=16, fontweight='bold')\n",
    "\n",
    "sensitivity_summary.plot(x='Classifier', y='Variance', kind='bar', ax=axes[0,0], color='coral', legend=False)\n",
    "axes[0,0].set_title('Variance')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "sensitivity_summary.plot(x='Classifier', y='Range', kind='bar', ax=axes[0,1], color='skyblue', legend=False)\n",
    "axes[0,1].set_title('Range')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "x_pos = np.arange(len(sensitivity_summary))\n",
    "axes[0,2].bar(x_pos - 0.2, sensitivity_summary['Best CV Score'], 0.4, label='CV')\n",
    "axes[0,2].bar(x_pos + 0.2, sensitivity_summary['Test Accuracy'], 0.4, label='Test')\n",
    "axes[0,2].set_xticks(x_pos)\n",
    "axes[0,2].set_xticklabels(sensitivity_summary['Classifier'], rotation=45)\n",
    "axes[0,2].legend()\n",
    "\n",
    "sensitivity_summary.plot(x='Classifier', y='Std Dev', kind='bar', ax=axes[1,0], color='mediumpurple', legend=False)\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "sensitivity_summary.plot(x='Classifier', y='Test F1', kind='bar', ax=axes[1,1], color='gold', legend=False)\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axes[1,2].scatter(sensitivity_summary['Variance'], sensitivity_summary['Test Accuracy'], s=200)\n",
    "for _, row in sensitivity_summary.iterrows():\n",
    "    axes[1,2].annotate(row['Classifier'], (row['Variance'], row['Test Accuracy']), fontsize=8)\n",
    "axes[1,2].set_xlabel('Variance')\n",
    "axes[1,2].set_ylabel('Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figures/wholesale_sensitivity_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Analysis complete for Wholesale Customers dataset\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693ebf23",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wholesale customers data\n",
    "df = pd.read_csv('wholesale/Wholesale customers data.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1616afd",
   "metadata": {},
   "source": [
    "## 2. Create Binary Classification Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea2e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total spending across all product categories\n",
    "product_cols = ['Fresh', 'Milk', 'Grocery', 'Frozen', 'Detergents_Paper', 'Delicassen']\n",
    "df['Total_Spending'] = df[product_cols].sum(axis=1)\n",
    "\n",
    "# Create binary target using median split\n",
    "# 0 = Low Spender (below median), 1 = High Spender (above median)\n",
    "median_spending = df['Total_Spending'].median()\n",
    "df['Spender_Class'] = (df['Total_Spending'] > median_spending).astype(int)\n",
    "\n",
    "print(f\"Median Total Spending: {median_spending:.2f}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['Spender_Class'].value_counts())\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "df['Total_Spending'].hist(bins=30, ax=axes[0], edgecolor='black')\n",
    "axes[0].axvline(median_spending, color='red', linestyle='--', label=f'Median={median_spending:.0f}')\n",
    "axes[0].set_title('Total Spending Distribution with Median Split')\n",
    "axes[0].set_xlabel('Total Spending')\n",
    "axes[0].legend()\n",
    "\n",
    "df['Spender_Class'].value_counts().plot(kind='bar', ax=axes[1], color=['skyblue', 'coral'])\n",
    "axes[1].set_title('Binary Class Distribution')\n",
    "axes[1].set_xlabel('Class')\n",
    "axes[1].set_xticklabels(['Low Spender', 'High Spender'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figures/wholesale_bucketing.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7ee9db",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9514f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features: Use product categories only (not Channel, Region)\n",
    "X = df[product_cols]\n",
    "y = df['Spender_Class']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7262ed",
   "metadata": {},
   "source": [
    "## 4. Train 6 Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe2f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', random_state=42),\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"WHOLESALE CUSTOMERS - TRAINING 6 CLASSIFIERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining: {name}\")\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    cv_scores = cross_val_score(clf, X_train_scaled, y_train, cv=3)\n",
    "    \n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'CV Mean': cv_scores.mean(),\n",
    "        'CV Std': cv_scores.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}, F1: {f1:.4f}, CV: {cv_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c9a9a",
   "metadata": {},
   "source": [
    "## 5. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d62517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).T.round(4)\n",
    "print(\"\\nFINAL RESULTS - WHOLESALE CUSTOMERS\")\n",
    "print(results_df)\n",
    "results_df.to_csv('outputs/results/wholesale_results.csv')\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "results_df['Accuracy'].plot(kind='bar', ax=axes[0,0], color='skyblue')\n",
    "axes[0,0].set_title('Accuracy Comparison')\n",
    "axes[0,0].set_ylim([0.7, 1.0])\n",
    "\n",
    "results_df['F1-Score'].plot(kind='bar', ax=axes[0,1], color='coral')\n",
    "axes[0,1].set_title('F1-Score Comparison')\n",
    "axes[0,1].set_ylim([0.7, 1.0])\n",
    "\n",
    "x_pos = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "axes[1,0].bar(x_pos - width/2, results_df['Precision'], width, label='Precision')\n",
    "axes[1,0].bar(x_pos + width/2, results_df['Recall'], width, label='Recall')\n",
    "axes[1,0].set_title('Precision vs Recall')\n",
    "axes[1,0].set_xticks(x_pos)\n",
    "axes[1,0].set_xticklabels(results_df.index, rotation=45)\n",
    "axes[1,0].legend()\n",
    "\n",
    "results_df[['Accuracy', 'Precision', 'Recall', 'F1-Score']].plot(kind='bar', ax=axes[1,1])\n",
    "axes[1,1].set_title('All Metrics')\n",
    "axes[1,1].set_ylim([0.7, 1.0])\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figures/wholesale_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "best_model = results_df['Accuracy'].idxmax()\n",
    "print(f\"\\nBest Model: {best_model} with Accuracy: {results_df.loc[best_model, 'Accuracy']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
